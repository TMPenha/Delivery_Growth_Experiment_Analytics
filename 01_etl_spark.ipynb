{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxG83ratA/XzdQpzQZT8Ms",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TMPenha/Delivery_Growth_Experiment_Analytics/blob/main/01_etl_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.GIT"
      ],
      "metadata": {
        "id": "z3g4oo6eJM4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf Delivery_Growth_Experiment_Analytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqsIVl8tKw9z",
        "outputId": "6af83dda-d10a-4e84-f941-95a19eb6bfb5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMn8ZQ6P-ZEV",
        "outputId": "5cfe2c64-a6a3-4ec6-b084-0bd3f15debbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Delivery_Growth_Experiment_Analytics'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "Receiving objects: 100% (12/12), 9.37 KiB | 1.56 MiB/s, done.\n",
            "remote: Total 12 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "/content/Delivery_Growth_Experiment_Analytics\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/TMPenha/Delivery_Growth_Experiment_Analytics.git\n",
        "%cd Delivery_Growth_Experiment_Analytics\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOb1v8q9MGkM",
        "outputId": "0337e263-5d15-4703-fa92-0bf34af04652"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Delivery_Growth_Experiment_Analytics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p notebooks\n",
        "!mkdir -p data\n",
        "!mkdir -p reports\n",
        "!mkdir -p src"
      ],
      "metadata": {
        "id": "N-6zDC6QMIfI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YthfA0QMLGS",
        "outputId": "e02f3854-b59a-4406-ca92-8ff9c34ae8fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  LICENSE  notebooks  README.md  reports  src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rtgRrrgMkpv",
        "outputId": "cd6ddb99-29f6-42ea-c2ca-bf856b1cf778"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Delivery_Growth_Experiment_Analytics  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/01_etl_spark.ipynb notebooks/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZHlQYuIDgu6",
        "outputId": "d7930d28-e10a-4aad-b9d1-64e36393206b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/01_etl_spark.ipynb': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls notebooks"
      ],
      "metadata": {
        "id": "wZ0ev-9-MPMi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"TMPenha\"\n",
        "!git config --global user.email \"thiagomalbar@email.com\""
      ],
      "metadata": {
        "id": "aoM-YuP-DpAK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7b0ttGoDqVK",
        "outputId": "367bfc1f-4850-4f67-e338-d75e5acec33e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "wzdc2_QUDrv6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"feat: add ETL spark notebook\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ja7RrlDKkMR",
        "outputId": "5b297994-b6c3-46ae-ad5e-ee95ce163272"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "TOKEN = getpass.getpass(\"Digite seu token: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gjf_XynKxpz",
        "outputId": "fca3c666-054b-457e-e13d-500274d1f32e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Digite seu token: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push https://{TOKEN}@github.com/TMPenha/Delivery_Growth_Experiment_Analytics.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q4qlGMlDtdJ",
        "outputId": "e1884ecc-b3d2-4365-93af-366977beff10"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#01. ETL\n",
        "\n",
        " ETL com Apache Spark - Growth Experiment Analytics\n",
        "\n"
      ],
      "metadata": {
        "id": "Hrte9oGsD-4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1Ô∏è‚É£ Instala (Colab-friendly)\n",
        "!pip install -q pyspark\n",
        "!pip install ijson"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di_30N5IO1vF",
        "outputId": "85e08acc-9978-4a20-9d7e-7e28afc3fb8d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ijson\n",
            "  Downloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Downloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (149 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/149.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ijson\n",
            "Successfully installed ijson-3.4.0.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2Ô∏è‚É£ Importa Spark\n",
        "\n",
        "import gzip, shutil, tarfile, urllib.request , json, os , ijson\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import FloatType\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, to_timestamp, to_date, when, lit\n",
        "\n"
      ],
      "metadata": {
        "id": "fpc3e8YuPLr8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Delivery Growth Experiment ETL\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"‚úÖ Spark Session criada com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rO-0un8PM-d",
        "outputId": "af580101-ee95-4ddf-d041-40ad8617bb24"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Spark Session criada com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Delivery Growth Experiment ETL\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark Session criada com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZjKqDZmO51M",
        "outputId": "24e29bd2-59cf-4203-cbde-51bc55da2fa0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark Session criada com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1Ô∏è‚É£ Instala√ß√µes e configura√ß√µes iniciais\n",
        "!apt-get install openjdk-11-jdk -qq\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark pyspark\n",
        "!pip install ijson\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_58FuCkCOIAZ",
        "outputId": "949f78ce-f153-4ec4-b17e-f43f4e22eeb1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/o/openjdk-lts/openjdk-11-jre-headless_11.0.29%2b7-1ubuntu1%7e22.04_amd64.deb  404  Not Found [IP: 91.189.91.81 80]\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/o/openjdk-lts/openjdk-11-jre_11.0.29%2b7-1ubuntu1%7e22.04_amd64.deb  404  Not Found [IP: 91.189.91.81 80]\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/o/openjdk-lts/openjdk-11-jdk-headless_11.0.29%2b7-1ubuntu1%7e22.04_amd64.deb  404  Not Found [IP: 91.189.91.81 80]\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/o/openjdk-lts/openjdk-11-jdk_11.0.29%2b7-1ubuntu1%7e22.04_amd64.deb  404  Not Found [IP: 91.189.91.81 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n",
            "tar: spark-3.4.1-bin-hadoop3.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: ijson in /usr/local/lib/python3.12/dist-packages (3.4.0.post0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/content/data\"\n",
        "\n",
        "RAW_DIR = f\"{BASE_DIR}/raw\"\n",
        "BRONZE_DIR = f\"{BASE_DIR}/bronze\"\n",
        "\n",
        "os.makedirs(RAW_DIR, exist_ok=True)\n",
        "os.makedirs(BRONZE_DIR, exist_ok=True)\n",
        "\n",
        "print(\"üìÅ Estrutura de pastas criada\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWpC7xXOl1co",
        "outputId": "f3fb9ebc-6cb8-421c-edf7-984c0c6e9432"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Estrutura de pastas criada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "03. Download e extra√ß√£o dos dados (RAW)"
      ],
      "metadata": {
        "id": "uA0hFh9emERK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Orders (JSON.GZ ‚Äì arquivo grande)"
      ],
      "metadata": {
        "id": "cs8oHjvxmGHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_url = \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/order.json.gz\"\n",
        "orders_path = f\"{RAW_DIR}/order.json.gz\"\n",
        "\n",
        "if not os.path.exists(orders_path):\n",
        "    urllib.request.urlretrieve(orders_url, orders_path)\n",
        "    print(\"‚úÖ orders baixado\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è orders j√° existe\")"
      ],
      "metadata": {
        "id": "aalYfsQimG_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consumers"
      ],
      "metadata": {
        "id": "Y0yjzuabmJt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "consumers_url = \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/consumer.csv.gz\"\n",
        "consumers_gz = f\"{RAW_DIR}/consumer.csv.gz\"\n",
        "consumers_csv = f\"{RAW_DIR}/consumer.csv\"\n",
        "\n",
        "urllib.request.urlretrieve(consumers_url, consumers_gz)\n",
        "\n",
        "with gzip.open(consumers_gz, \"rb\") as f_in, open(consumers_csv, \"wb\") as f_out:\n",
        "    shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "print(\"‚úÖ consumers extra√≠do\")"
      ],
      "metadata": {
        "id": "sSH67C7EmI2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restaurants"
      ],
      "metadata": {
        "id": "m9cI2T-bmK28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "restaurants_url = \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/restaurant.csv.gz\"\n",
        "restaurants_gz = f\"{RAW_DIR}/restaurant.csv.gz\"\n",
        "restaurants_csv = f\"{RAW_DIR}/restaurant.csv\"\n",
        "\n",
        "urllib.request.urlretrieve(restaurants_url, restaurants_gz)\n",
        "\n",
        "with gzip.open(restaurants_gz, \"rb\") as f_in, open(restaurants_csv, \"wb\") as f_out:\n",
        "    shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "print(\"‚úÖ restaurants extra√≠do\")"
      ],
      "metadata": {
        "id": "I7ZXdZT9mLz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AB Test Reference"
      ],
      "metadata": {
        "id": "wVKz9XmqmNVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab_url = \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/ab_test_ref.tar.gz\"\n",
        "ab_tar = f\"{RAW_DIR}/ab_test_ref.tar.gz\"\n",
        "\n",
        "urllib.request.urlretrieve(ab_url, ab_tar)\n",
        "\n",
        "with tarfile.open(ab_tar, \"r:gz\") as tar:\n",
        "    tar.extractall(path=RAW_DIR)\n",
        "\n",
        "print(\"‚úÖ ab_test_ref extra√≠do\")"
      ],
      "metadata": {
        "id": "cM08iKA0mOXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "04. Leitura dos dados no Spark (RAW)"
      ],
      "metadata": {
        "id": "wxRhCKrCmR1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Orders (solu√ß√£o correta para JSON gigante)"
      ],
      "metadata": {
        "id": "jefiXUkjmTW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df = (\n",
        "    spark.read\n",
        "    .option(\"mode\", \"PERMISSIVE\")\n",
        "    .option(\"columnNameOfCorruptRecord\", \"_corrupt_record\")\n",
        "    .json(orders_path)\n",
        ")"
      ],
      "metadata": {
        "id": "llZg2CAxmU89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consumers / Restaurants / AB Test"
      ],
      "metadata": {
        "id": "F-33C9OwmWQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "consumers_df = spark.read.option(\"header\", True).csv(consumers_csv)\n",
        "restaurants_df = spark.read.option(\"header\", True).csv(restaurants_csv)\n",
        "ab_test_df = spark.read.option(\"header\", True).csv(f\"{RAW_DIR}/ab_test_ref.csv\")"
      ],
      "metadata": {
        "id": "TcoXj9XEmXGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "05. Valida√ß√£o da camada RAW (output agrupado)"
      ],
      "metadata": {
        "id": "FNfBMHUJmYMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìä DATASETS ‚Äì CAMADA RAW\\n\")\n",
        "\n",
        "datasets_summary = []\n",
        "\n",
        "# Orders\n",
        "orders_total = orders_df.count()\n",
        "corrupt_count = (\n",
        "    orders_df.filter(F.col(\"_corrupt_record\").isNotNull()).count()\n",
        "    if \"_corrupt_record\" in orders_df.columns else 0\n",
        ")\n",
        "datasets_summary.append((\"orders\", orders_total, corrupt_count))\n",
        "\n",
        "# Consumers\n",
        "datasets_summary.append((\"consumers\", consumers_df.count(), 0))\n",
        "\n",
        "# Restaurants\n",
        "datasets_summary.append((\"restaurants\", restaurants_df.count(), 0))\n",
        "\n",
        "# AB Test\n",
        "datasets_summary.append((\"ab_test\", ab_test_df.count(), 0))"
      ],
      "metadata": {
        "id": "Ip2sjeAQmZd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_raw_df = spark.createDataFrame(\n",
        "    datasets_summary,\n",
        "    [\"dataset\", \"total_registros\", \"registros_corrompidos\"]\n",
        ")\n",
        "\n",
        "summary_raw_df = summary_raw_df.withColumn(\n",
        "    \"status\",\n",
        "    F.when(F.col(\"registros_corrompidos\") > 0, \"‚ö†Ô∏è ATEN√á√ÉO\")\n",
        "     .otherwise(\"‚úÖ OK\")\n",
        ")\n",
        "\n",
        "summary_raw_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "NcGKRsssma0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "06. Ajustes b√°sicos de tipos (RAW ‚Üí BRONZE)"
      ],
      "metadata": {
        "id": "_ZaAgYG5mccx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, to_date\n"
      ],
      "metadata": {
        "id": "kV6QSR2_mdjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_bronze_df = (\n",
        "    orders_df\n",
        "    # Coordenadas\n",
        "    .withColumn(\"delivery_address_latitude\", col(\"delivery_address_latitude\").cast(\"double\"))\n",
        "    .withColumn(\"delivery_address_longitude\", col(\"delivery_address_longitude\").cast(\"double\"))\n",
        "    .withColumn(\"merchant_latitude\", col(\"merchant_latitude\").cast(\"double\"))\n",
        "    .withColumn(\"merchant_longitude\", col(\"merchant_longitude\").cast(\"double\"))\n",
        "\n",
        "    # Datas\n",
        "    .withColumn(\n",
        "        \"order_scheduled_date\",\n",
        "        to_date(col(\"order_scheduled_date\"))\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "ndK4b3CXmeXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "consumers_bronze_df = (\n",
        "    consumers_df\n",
        "    .withColumn(\"active\", col(\"active\").cast(\"boolean\"))\n",
        ")\n"
      ],
      "metadata": {
        "id": "5P_FW8wTmfBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurants_bronze_df = (\n",
        "    restaurants_df\n",
        "    .withColumn(\"created_at\", to_timestamp(col(\"created_at\")))\n",
        "    .withColumn(\"enabled\", col(\"enabled\").cast(\"boolean\"))\n",
        "    .withColumn(\"price_range\", col(\"price_range\").cast(\"int\"))\n",
        "    .withColumn(\"average_ticket\", col(\"average_ticket\").cast(\"double\"))\n",
        "    .withColumn(\"takeout_time\", col(\"takeout_time\").cast(\"int\"))\n",
        "    .withColumn(\"delivery_time\", col(\"delivery_time\").cast(\"int\"))\n",
        "    .withColumn(\"minimum_order_value\", col(\"minimum_order_value\").cast(\"double\"))\n",
        ")\n"
      ],
      "metadata": {
        "id": "w4deibQ-mgxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ab_test_bronze_df = ab_test_df\n"
      ],
      "metadata": {
        "id": "SlOmu3V8unuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "07. Escrita da camada BRONZE (Parquet)"
      ],
      "metadata": {
        "id": "8etQnYukmhvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.catalog.clearCache()"
      ],
      "metadata": {
        "id": "SSvMJwLRwOHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df = orders_df.cache()\n",
        "consumers_df = consumers_df.cache()\n",
        "restaurants_df = restaurants_df.cache()\n",
        "ab_test_df = ab_test_df.cache()\n",
        "\n",
        "# for√ßa a execu√ß√£o\n",
        "orders_df.count()\n",
        "consumers_df.count()\n",
        "restaurants_df.count()\n",
        "ab_test_df.count()\n"
      ],
      "metadata": {
        "id": "TwG3r0rGwPIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "if os.path.exists(BRONZE_DIR):\n",
        "    shutil.rmtree(BRONZE_DIR)\n"
      ],
      "metadata": {
        "id": "XDIMP7NlwQK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df.write.mode(\"overwrite\").parquet(f\"{BRONZE_DIR}/orders\")\n",
        "consumers_df.write.mode(\"overwrite\").parquet(f\"{BRONZE_DIR}/consumers\")\n",
        "restaurants_df.write.mode(\"overwrite\").parquet(f\"{BRONZE_DIR}/restaurants\")\n",
        "ab_test_df.write.mode(\"overwrite\").parquet(f\"{BRONZE_DIR}/ab_test\")\n",
        "\n",
        "print(\"‚úÖ Camada BRONZE criada com sucesso\")\n"
      ],
      "metadata": {
        "id": "7U9BCPqIwROf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "08. Valida√ß√£o da camada BRONZE"
      ],
      "metadata": {
        "id": "Nt4b6gCpmkOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìä DATASETS ‚Äì CAMADA BRONZE\\n\")\n",
        "\n",
        "bronze_summary = [\n",
        "    (\"orders\", spark.read.parquet(f\"{BRONZE_DIR}/orders\").count()),\n",
        "    (\"consumers\", spark.read.parquet(f\"{BRONZE_DIR}/consumers\").count()),\n",
        "    (\"restaurants\", spark.read.parquet(f\"{BRONZE_DIR}/restaurants\").count()),\n",
        "    (\"ab_test\", spark.read.parquet(f\"{BRONZE_DIR}/ab_test\").count())\n",
        "]\n"
      ],
      "metadata": {
        "id": "E_CtKicnmlOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.createDataFrame(\n",
        "    bronze_summary,\n",
        "    [\"dataset\", \"total_registros\"]\n",
        ").show(truncate=False)\n"
      ],
      "metadata": {
        "id": "1aTU5zVxmmAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "09. Encerramento"
      ],
      "metadata": {
        "id": "4yjOyGrqmnB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üéØ ETL conclu√≠do com sucesso.\")\n",
        "print(\"Pronto para o notebook 02_ab_analysis.ipynb\")\n"
      ],
      "metadata": {
        "id": "SxJ5dE0omn_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß© DRAW.iO"
      ],
      "metadata": {
        "id": "BeeX8QRZmoyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df = spark.read.parquet(\"/content/data/bronze/orders\")\n",
        "consumers_df = spark.read.parquet(\"/content/data/bronze/consumers\")\n",
        "restaurants_df = spark.read.parquet(\"/content/data/bronze/restaurants\")\n",
        "ab_test_df = spark.read.parquet(\"/content/data/bronze/ab_test\")\n"
      ],
      "metadata": {
        "id": "3wNy-IRcqVo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_table_schema(table_name, df, pk=None, fks=None):\n",
        "    print(f\"\\nüì¶ TABLE: {table_name}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for field in df.schema.fields:\n",
        "        col = field.name\n",
        "        dtype = field.dataType.simpleString()\n",
        "\n",
        "        tags = []\n",
        "        if pk and col in pk:\n",
        "            tags.append(\"PK\")\n",
        "        if fks and col in fks:\n",
        "            tags.append(f\"FK ‚Üí {fks[col]}\")\n",
        "\n",
        "        tag_str = f\" [{', '.join(tags)}]\" if tags else \"\"\n",
        "        print(f\"- {col}: {dtype}{tag_str}\")\n"
      ],
      "metadata": {
        "id": "8IMmIFZeqXFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üß© MODELO RELACIONAL ‚Äì DATASETS BRONZE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Orders\n",
        "print_table_schema(\n",
        "    table_name=\"orders\",\n",
        "    df=orders_df,\n",
        "    pk=[\"order_id\"],\n",
        "    fks={\n",
        "        \"customer_id\": \"consumers.customer_id\",\n",
        "        \"merchant_id\": \"restaurants.id\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Consumers\n",
        "print_table_schema(\n",
        "    table_name=\"consumers\",\n",
        "    df=consumers_df,\n",
        "    pk=[\"customer_id\"]\n",
        ")\n",
        "\n",
        "# Restaurants\n",
        "print_table_schema(\n",
        "    table_name=\"restaurants\",\n",
        "    df=restaurants_df,\n",
        "    pk=[\"id\"]\n",
        ")\n",
        "\n",
        "# AB Test\n",
        "print_table_schema(\n",
        "    table_name=\"ab_test\",\n",
        "    df=ab_test_df,\n",
        "    pk=None,\n",
        "    fks={\n",
        "        \"customer_id\": \"consumers.customer_id\"\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "il1hxCKAqd1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preview_table(df, table_name, n=5):\n",
        "    print(f\"\\nüì¶ TABELA: {table_name}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(\"Schema:\")\n",
        "    df.printSchema()\n",
        "    print(\"\\nAmostra de dados:\")\n",
        "    df.show(n, truncate=False)\n"
      ],
      "metadata": {
        "id": "A2mw7yebtrYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preview_table(orders_df, \"orders\")\n",
        "preview_table(consumers_df, \"consumers\")\n",
        "preview_table(restaurants_df, \"restaurants\")\n",
        "preview_table(ab_test_df, \"ab_test\")"
      ],
      "metadata": {
        "id": "iRvzKnUJtspK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}